---
marp: true
theme: default
paginate: true
backgroundColor: #fff
style: |
  @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&family=Fira+Code&display=swap');
  @import 'custom.css';
---

<!-- _class: lead -->

# Week 7: Building Your First ML Models

**CS 203: Software Tools and Techniques for AI**

Prof. Nipun Batra
IIT Gandhinagar

---

<!-- _class: lead -->

# Part 1: The Big Picture

*What does it mean to "build" an ML model?*

---

# Remember Our Netflix Journey?

```
Week 1: Collected movie data (APIs, scraping)
Week 2: Cleaned and organized it (Pandas)
Week 3: Labeled movie success/failure (annotation)
Week 4: Made labeling efficient (active learning)
Week 5: Got more data (augmentation)
Week 6: Used LLMs to help (APIs)
        â†“
Week 7: NOW WE BUILD THE MODEL! ğŸ‰
```

**We finally have good data. Time to predict!**

---

# What Are We Predicting?

**Our Netflix Problem**:
Given movie features â†’ Predict if it will be successful

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  INPUT (What we know)           OUTPUT (What we predict)        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€        â”‚
â”‚  â€¢ Genre: Action                                                â”‚
â”‚  â€¢ Budget: $150M                 â†’ SUCCESS or FAILURE?          â”‚
â”‚  â€¢ Director: Nolan                                              â”‚
â”‚  â€¢ Runtime: 148 mins                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

This is called **Classification** (putting things in categories)

---

# Two Types of Predictions

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       CLASSIFICATION            â”‚  â”‚         REGRESSION              â”‚
â”‚                                 â”‚  â”‚                                 â”‚
â”‚   Predict a CATEGORY            â”‚  â”‚   Predict a NUMBER              â”‚
â”‚                                 â”‚  â”‚                                 â”‚
â”‚   â€¢ Success / Failure           â”‚  â”‚   â€¢ $500M revenue               â”‚
â”‚   â€¢ Spam / Not Spam             â”‚  â”‚   â€¢ 7.5 rating                  â”‚
â”‚   â€¢ Cat / Dog / Bird            â”‚  â”‚   â€¢ 25Â°C temperature            â”‚
â”‚                                 â”‚  â”‚                                 â”‚
â”‚   "Which box does this go in?"  â”‚  â”‚   "How much / How many?"        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Today**: We'll focus on classification (predicting movie success)

---

# The ML Workflow (Simple Version)

```
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Your Data   â”‚
    â”‚  (movies.csv)â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Split Data   â”‚  â†â”€â”€ Training set + Test set
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Train Model  â”‚  â†â”€â”€ Model learns patterns
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Evaluate     â”‚  â†â”€â”€ How good is it?
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Simple!** But the devil is in the details...

---

<!-- _class: lead -->

# Part 2: Starting Simple - Baseline Models

*Why you should never start with deep learning*

---

# The Temptation

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚    You: "I want to predict movie success!"                      â”‚
â”‚                                                                 â”‚
â”‚    Internet: "Use a 175-billion parameter neural network!"      â”‚
â”‚                                                                 â”‚
â”‚    You: "Sounds cool! Let me try..."                           â”‚
â”‚                                                                 â”‚
â”‚    3 hours later: ğŸ”¥ğŸ’€ğŸ˜­                                        â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**DON'T DO THIS!**

---

# What is a Baseline?

A **baseline** is the simplest possible solution that works.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BASELINE EXAMPLES                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  Task: Predict if movie succeeds                              â”‚
â”‚                                                               â”‚
â”‚  Dumb Baseline: "Just predict the most common outcome"        â”‚
â”‚                 If 70% of movies succeed â†’ always say SUCCESS â”‚
â”‚                 Accuracy: 70% (for free!)                     â”‚
â”‚                                                               â”‚
â”‚  Simple Model:  Logistic Regression                           â”‚
â”‚                 (One line of code, 80% accuracy?)             â”‚
â”‚                                                               â”‚
â”‚  Complex Model: Deep Neural Network                           â”‚
â”‚                 (1000 lines of code, 82% accuracy?)           â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Is that 2% worth 100x complexity?**

---

# Why Baselines Matter

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚   Scenario 1: You build a fancy model, get 85% accuracy         â”‚
â”‚               â†’ "Wow, my model is amazing!"                     â”‚
â”‚                                                                 â”‚
â”‚   Reality:    A baseline gets 84% accuracy                      â”‚
â”‚               â†’ Your fancy model only improved by 1%            â”‚
â”‚               â†’ All that complexity for nothing ğŸ˜…               â”‚
â”‚                                                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   Scenario 2: You build a fancy model, get 85% accuracy         â”‚
â”‚               Baseline gets 60% accuracy                        â”‚
â”‚               â†’ Your model improved by 25%!                     â”‚
â”‚               â†’ That complexity was worth it! ğŸ‰                 â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Baselines give you a reference point.**

---

# The Simplest Baseline: "Just Guess"

```python
# The dumbest model possible
def dumb_predictor(movie):
    return "SUCCESS"  # Always predict success

# If 70% of movies succeed, this gets 70% accuracy!
```

**This is called a "Majority Class Classifier"**

```python
from sklearn.dummy import DummyClassifier

# Create the dumbest possible classifier
baseline = DummyClassifier(strategy='most_frequent')
baseline.fit(X_train, y_train)

accuracy = baseline.score(X_test, y_test)
print(f"Dumb baseline accuracy: {accuracy:.1%}")
```

**Any real model must beat this!**

---

# Baseline Model 1: Logistic Regression

**Think of it as**: A weighing scale for features

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚   Feature             Weight      Value       Contribution      â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”€â”€â”€â”€â”€â”€      â”€â”€â”€â”€â”€       â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€      â”‚
â”‚   Budget ($M)         +0.3        150         +45               â”‚
â”‚   Star Power          +0.5        8           +4                â”‚
â”‚   Is Sequel           +0.2        1           +0.2              â”‚
â”‚   Is January Release  -0.4        0           0                 â”‚
â”‚                                               â”€â”€â”€â”€â”€             â”‚
â”‚                                   Total:      +49.2             â”‚
â”‚                                                                 â”‚
â”‚   If Total > 0 â†’ Predict SUCCESS                                â”‚
â”‚   If Total < 0 â†’ Predict FAILURE                                â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**It just adds up weighted features!**

---

# Logistic Regression in Code

```python
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split

# Split data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(
    features, labels, test_size=0.2, random_state=42
)

# Create and train the model (2 lines!)
model = LogisticRegression()
model.fit(X_train, y_train)

# Evaluate
accuracy = model.score(X_test, y_test)
print(f"Logistic Regression accuracy: {accuracy:.1%}")
```

**That's it! A working ML model in 4 lines.**

---

# Baseline Model 2: Decision Tree

**Think of it as**: A flowchart of yes/no questions

```
                         Is Budget > $100M?
                        /                  \
                      YES                   NO
                      /                      \
               Is Sequel?              Has Star Actor?
               /        \               /          \
             YES        NO            YES          NO
             /           \            /             \
         SUCCESS      Is Summer?   FAILURE      SUCCESS
                       /     \
                     YES     NO
                     /        \
                SUCCESS    FAILURE
```

**Humans can actually read and understand this!**

---

# Decision Tree in Code

```python
from sklearn.tree import DecisionTreeClassifier

# Create and train
tree = DecisionTreeClassifier(max_depth=5)  # Don't go too deep!
tree.fit(X_train, y_train)

# Evaluate
accuracy = tree.score(X_test, y_test)
print(f"Decision Tree accuracy: {accuracy:.1%}")
```

**You can even visualize it:**

```python
from sklearn.tree import plot_tree
import matplotlib.pyplot as plt

plt.figure(figsize=(20, 10))
plot_tree(tree, feature_names=feature_names, filled=True)
plt.show()
```

---

# Which Baseline to Use?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   BASELINE SELECTION GUIDE                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Your Situation           â”‚  Recommended Baseline               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Just starting            â”‚  Logistic Regression                â”‚
â”‚                           â”‚  (fast, simple, often works well)   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Need interpretability    â”‚  Decision Tree                      â”‚
â”‚  (explain to your boss)   â”‚  (you can see the rules)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Mixed data types         â”‚  Random Forest                      â”‚
â”‚  (numbers + categories)   â”‚  (handles everything)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Want best performance    â”‚  AutoML (we'll learn this later!)   â”‚
â”‚  (don't care how)         â”‚                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Baseline Model 3: Random Forest

**Think of it as**: Asking 100 decision trees and taking a vote

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚   Tree 1: "I think SUCCESS"  â”€â”€â”                                â”‚
â”‚   Tree 2: "I think FAILURE"    â”‚                                â”‚
â”‚   Tree 3: "I think SUCCESS"    â”‚                                â”‚
â”‚   Tree 4: "I think SUCCESS"    â”œâ”€â”€â–º  VOTE: SUCCESS wins!        â”‚
â”‚   Tree 5: "I think FAILURE"    â”‚           (3 vs 2)             â”‚
â”‚   ...                          â”‚                                â”‚
â”‚   Tree 100: "I think SUCCESS"â”€â”€â”˜                                â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Wisdom of crowds**: Many weak learners â†’ One strong learner

---

# Random Forest in Code

```python
from sklearn.ensemble import RandomForestClassifier

# Create and train
forest = RandomForestClassifier(n_estimators=100, random_state=42)
forest.fit(X_train, y_train)

# Evaluate
accuracy = forest.score(X_test, y_test)
print(f"Random Forest accuracy: {accuracy:.1%}")
```

**Often the best simple model!** Very hard to beat.

---

<!-- _class: lead -->

# Part 3: Cross-Validation

*How to really know if your model is good*

---

# The Problem with One Test Set

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚   Scenario: You split your data ONCE                            â”‚
â”‚                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚   â”‚        Training (80%)        â”‚  Test (20%)  â”‚               â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                                 â”‚
â”‚   Your model gets 85% on the test set. Great?                   â”‚
â”‚                                                                 â”‚
â”‚   BUT WAIT... What if you got "lucky" with that split?          â”‚
â”‚   What if the test set happened to be easy?                     â”‚
â”‚   What if you accidentally put all the hard movies in training? â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**One test set = One roll of the dice ğŸ²**

---

# The Solution: Cross-Validation

**Idea**: Test on EVERY part of your data (not just 20%)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     5-FOLD CROSS-VALIDATION                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Fold 1: [TEST][Train][Train][Train][Train]  â†’ Accuracy: 82%    â”‚
â”‚  Fold 2: [Train][TEST][Train][Train][Train]  â†’ Accuracy: 85%    â”‚
â”‚  Fold 3: [Train][Train][TEST][Train][Train]  â†’ Accuracy: 84%    â”‚
â”‚  Fold 4: [Train][Train][Train][TEST][Train]  â†’ Accuracy: 81%    â”‚
â”‚  Fold 5: [Train][Train][Train][Train][TEST]  â†’ Accuracy: 83%    â”‚
â”‚                                                                 â”‚
â”‚  Average: 83% Â± 1.5%                                            â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Now we know**: "My model gets ~83% accuracy, give or take 1.5%"

---

# Cross-Validation: Visual Intuition

Think of it like a **rotating exam schedule**:

```
          Split 1        Split 2        Split 3        Split 4        Split 5
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
Student â”‚ â–ˆ â–ˆ â–ˆ â–ˆ â”‚    â”‚ â–‘ â–ˆ â–ˆ â–ˆ â”‚    â”‚ â–‘ â–‘ â–ˆ â–ˆ â”‚    â”‚ â–‘ â–‘ â–‘ â–ˆ â”‚    â”‚ â–‘ â–‘ â–‘ â–‘ â”‚
  A     â”‚(exam)   â”‚    â”‚(study)  â”‚    â”‚(study)  â”‚    â”‚(study)  â”‚    â”‚(study)  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
Student â”‚ â–‘ â–‘ â–‘ â–‘ â”‚    â”‚ â–ˆ â–ˆ â–ˆ â–ˆ â”‚    â”‚ â–‘ â–‘ â–‘ â–‘ â”‚    â”‚ â–‘ â–‘ â–‘ â–‘ â”‚    â”‚ â–‘ â–‘ â–‘ â–‘ â”‚
  B     â”‚(study)  â”‚    â”‚(exam)   â”‚    â”‚(study)  â”‚    â”‚(study)  â”‚    â”‚(study)  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â–ˆ = Test (exam)    â–‘ = Train (study)
```

**Every data point gets tested exactly once!**

---

# Cross-Validation in Code

```python
from sklearn.model_selection import cross_val_score

# Create model
model = RandomForestClassifier(n_estimators=100)

# Run 5-fold cross-validation
scores = cross_val_score(model, X, y, cv=5)

print(f"Scores for each fold: {scores}")
print(f"Average accuracy: {scores.mean():.1%}")
print(f"Standard deviation: {scores.std():.1%}")
```

**Output:**
```
Scores for each fold: [0.82, 0.85, 0.84, 0.81, 0.83]
Average accuracy: 83.0%
Standard deviation: 1.5%
```

---

# Why Cross-Validation Matters

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      MODEL COMPARISON                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Model             â”‚  Single Test â”‚  5-Fold CV                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Logistic Reg.     â”‚     78%      â”‚  76% Â± 2%                   â”‚
â”‚  Decision Tree     â”‚     82%      â”‚  75% Â± 5%  â† High variance! â”‚
â”‚  Random Forest     â”‚     84%      â”‚  83% Â± 1%  â† Most stable!   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Insights**:
- Decision Tree looked good on one test, but it's unstable
- Random Forest is not only accurate but **consistent**

**Cross-validation reveals the truth!**

---

# Quick Summary So Far

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     WHAT WE LEARNED                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  1. BASELINES: Always start simple                              â”‚
â”‚     â€¢ Majority classifier (the dumbest possible)                â”‚
â”‚     â€¢ Logistic Regression (weighted sum of features)            â”‚
â”‚     â€¢ Decision Tree (flowchart of rules)                        â”‚
â”‚     â€¢ Random Forest (voting committee of trees)                 â”‚
â”‚                                                                 â”‚
â”‚  2. CROSS-VALIDATION: Test on all your data                     â”‚
â”‚     â€¢ Split data into 5 (or 10) folds                           â”‚
â”‚     â€¢ Each fold takes a turn being the test set                 â”‚
â”‚     â€¢ Get average Â± standard deviation                          â”‚
â”‚     â€¢ Much more reliable than a single test set                 â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

<!-- _class: lead -->

# Part 4: AutoML - Let the Computer Do It

*The lazy (smart) way to build models*

---

# The Problem with Manual ML

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BUILDING ML MODELS MANUALLY                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  1. Try Logistic Regression... okay                             â”‚
â”‚  2. Try Decision Tree... not great                              â”‚
â”‚  3. Try Random Forest... better                                 â”‚
â”‚  4. Try XGBoost... hmm, similar                                 â”‚
â”‚  5. Try Neural Network... takes forever                         â”‚
â”‚  6. Tune hyperparameters for each...                            â”‚
â”‚  7. Try different feature combinations...                       â”‚
â”‚  8. Repeat steps 1-7 many times...                              â”‚
â”‚                                                                 â”‚
â”‚  Time spent: 3 days                                             â”‚
â”‚  Hair remaining: None                                           â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**There has to be a better way!**

---

# Enter AutoML

**AutoML** = Automatic Machine Learning

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚   You: "Here's my data. Give me the best model."                â”‚
â”‚                                                                 â”‚
â”‚   AutoML: "On it! Let me try 50 different models,               â”‚
â”‚            tune their parameters, combine the best ones,        â”‚
â”‚            and give you a super-ensemble."                      â”‚
â”‚                                                                 â”‚
â”‚   You: *goes to get coffee*                                     â”‚
â”‚                                                                 â”‚
â”‚   AutoML: "Done! Here's a model with 87% accuracy."             â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**This is not magic. It just automates what experts do manually.**

---

# AutoGluon: AutoML Made Easy

**AutoGluon** (by Amazon) is one of the best AutoML tools.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   WHAT AUTOGLUON DOES                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  1. Automatically handles missing values                        â”‚
â”‚  2. Automatically encodes categorical features                  â”‚
â”‚  3. Trains multiple model types:                                â”‚
â”‚     â€¢ Random Forest                                             â”‚
â”‚     â€¢ XGBoost, LightGBM, CatBoost (gradient boosting)          â”‚
â”‚     â€¢ Neural Networks                                           â”‚
â”‚     â€¢ And more...                                               â”‚
â”‚  4. Tunes hyperparameters                                       â”‚
â”‚  5. Creates an ensemble of the best models                      â”‚
â”‚  6. Uses cross-validation internally                            â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# AutoGluon in 3 Lines of Code

```python
from autogluon.tabular import TabularPredictor

# Step 1: Create the predictor
predictor = TabularPredictor(label='success')

# Step 2: Train on your data (that's it!)
predictor.fit(train_data)

# Step 3: Make predictions
predictions = predictor.predict(test_data)
```

**Seriously. That's the entire code.**

---

# What Happens Inside AutoGluon?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  AUTOGLUON TRAINING PROCESS                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Input: Your CSV file                                           â”‚
â”‚          â†“                                                      â”‚
â”‚  Step 1: Analyze data types (numbers, text, dates)              â”‚
â”‚          â†“                                                      â”‚
â”‚  Step 2: Preprocess features automatically                      â”‚
â”‚          â†“                                                      â”‚
â”‚  Step 3: Train 10+ different model types                        â”‚
â”‚          â†“                                                      â”‚
â”‚  Step 4: Cross-validate each model                              â”‚
â”‚          â†“                                                      â”‚
â”‚  Step 5: Stack models together (ensemble)                       â”‚
â”‚          â†“                                                      â”‚
â”‚  Output: One super-model that combines the best of all          â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# AutoGluon Leaderboard

After training, you can see how each model performed:

```python
predictor.leaderboard(test_data)
```

```
                model  score_val  fit_time
0   WeightedEnsemble_L2     0.87      120s
1             CatBoost     0.85       45s
2             LightGBM     0.84       30s
3              XGBoost     0.83       50s
4         RandomForest     0.82       25s
5   NeuralNetFastAI     0.80       90s
6     LogisticRegression  0.76        5s
```

**The ensemble combines the best models!**

---

# When to Use AutoML

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              WHEN TO USE AUTOML                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  âœ… Great for:                                                   â”‚
â”‚     â€¢ Quick prototyping ("Is ML even useful for this?")         â”‚
â”‚     â€¢ Competitions (Kaggle)                                     â”‚
â”‚     â€¢ When you don't have ML expertise                          â”‚
â”‚     â€¢ Setting a strong baseline to beat                         â”‚
â”‚                                                                 â”‚
â”‚  âš ï¸ Be careful:                                                  â”‚
â”‚     â€¢ Takes a long time to train (10 mins to hours)             â”‚
â”‚     â€¢ Uses lots of memory                                       â”‚
â”‚     â€¢ Hard to explain ("Why did it predict this?")              â”‚
â”‚     â€¢ Model might be too big for production                     â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# AutoGluon with Time Limit

**Don't have all day?** Set a time limit:

```python
predictor = TabularPredictor(label='success')

# Only train for 5 minutes
predictor.fit(train_data, time_limit=300)  # 300 seconds = 5 mins
```

**More time = Better models** (usually)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Time Limit  â”‚  What AutoGluon Can Do                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1 minute    â”‚  Quick baselines (RF, LR)                       â”‚
â”‚  5 minutes   â”‚  Good models (+ XGBoost, LightGBM)              â”‚
â”‚  30 minutes  â”‚  Great models (+ Neural Nets, tuning)           â”‚
â”‚  2+ hours    â”‚  Best possible (full tuning, stacking)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

<!-- _class: lead -->

# Part 5: Transfer Learning

*Standing on the shoulders of giants*

---

# The Problem with Training from Scratch

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TRAINING A NEW MODEL                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Scenario: You want to classify movie posters (images)          â”‚
â”‚                                                                 â”‚
â”‚  Option 1: Train from scratch                                   â”‚
â”‚  â€¢ Need: 1 million labeled images                               â”‚
â”‚  â€¢ Need: 10 GPUs for a week                                     â”‚
â”‚  â€¢ Need: ML PhD to get it right                                 â”‚
â”‚  â€¢ Cost: $10,000+                                               â”‚
â”‚                                                                 â”‚
â”‚  Option 2: Use someone else's model                             â”‚
â”‚  â€¢ Need: 1,000 labeled images                                   â”‚
â”‚  â€¢ Need: 1 GPU for an hour                                      â”‚
â”‚  â€¢ Need: Basic Python skills                                    â”‚
â”‚  â€¢ Cost: $1                                                     â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Transfer Learning: The Analogy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              LEARNING TO PLAY A NEW SPORT                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Someone who has NEVER played any sport:                        â”‚
â”‚  â€¢ Learning tennis takes 6 months                               â”‚
â”‚  â€¢ Starts from zero                                             â”‚
â”‚                                                                 â”‚
â”‚  Someone who plays badminton:                                   â”‚
â”‚  â€¢ Learning tennis takes 2 months                               â”‚
â”‚  â€¢ Already knows: hand-eye coordination, racket grip,           â”‚
â”‚    court movement, strategy                                     â”‚
â”‚  â€¢ Just needs to learn: different swing, ball bounce            â”‚
â”‚                                                                 â”‚
â”‚  The badminton player TRANSFERS their skills!                   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Transfer Learning**: Use knowledge from one task for another.

---

# How Transfer Learning Works for Images

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PRETRAINED IMAGE MODEL                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Google trained a model on 14 MILLION images (ImageNet)         â”‚
â”‚                                                                 â”‚
â”‚  What it learned (bottom to top):                               â”‚
â”‚                                                                 â”‚
â”‚  Layer 1: Edges         â–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆ                        â”‚
â”‚                         â”€â”€â”€   â•±â•²    â—¡                           â”‚
â”‚                                                                 â”‚
â”‚  Layer 2: Textures      â–‘â–‘â–‘   â–“â–“â–“   â•³â•³â•³                         â”‚
â”‚                                                                 â”‚
â”‚  Layer 3: Shapes        â—¯     â–¡     â–³                           â”‚
â”‚                                                                 â”‚
â”‚  Layer 4: Objects       ğŸ±    ğŸš—    ğŸŒ³                           â”‚
â”‚                                                                 â”‚
â”‚  Layer 5: Scenes        ğŸ  ğŸŒ… ğŸ¬                                 â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Lower layers = Universal features (edges, textures)**
**Higher layers = Task-specific features (cats, cars)**

---

# Transfer Learning Strategy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    THE TRANSFER RECIPE                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Step 1: Take a pretrained model (trained on millions of        â”‚
â”‚          images by Google/Facebook)                             â”‚
â”‚                                                                 â”‚
â”‚  Step 2: Remove the last layer (the "head")                     â”‚
â”‚          â€¢ Original: predicts 1000 ImageNet categories          â”‚
â”‚          â€¢ We don't need "cat", "dog", "airplane"               â”‚
â”‚                                                                 â”‚
â”‚  Step 3: Add our own head                                       â”‚
â”‚          â€¢ New layer: predicts OUR categories                   â”‚
â”‚          â€¢ Movie poster â†’ "Action", "Comedy", "Drama"           â”‚
â”‚                                                                 â”‚
â”‚  Step 4: Train only the new head (freeze everything else)       â”‚
â”‚          â€¢ Very fast! (minutes instead of days)                 â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Transfer Learning Visualized

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚   PRETRAINED MODEL              YOUR NEW MODEL                  â”‚
â”‚   (from Google)                 (for movies)                    â”‚
â”‚                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚   â”‚ Cat/Dog/Car â”‚  â”€â”€REMOVEâ”€â”€â–º  â”‚ Action/     â”‚  â† NEW!         â”‚
â”‚   â”‚   (1000)    â”‚               â”‚ Comedy/Dramaâ”‚                 â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚         â†‘                             â†‘                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚   â”‚ Shapes      â”‚  â”€â”€KEEPâ”€â”€â”€â”€â–º  â”‚ Shapes      â”‚  â† FROZEN       â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚         â†‘                             â†‘                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚   â”‚ Edges       â”‚  â”€â”€KEEPâ”€â”€â”€â”€â–º  â”‚ Edges       â”‚  â† FROZEN       â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Transfer Learning for Text (LLMs)

Same idea works for text!

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   PRETRAINED TEXT MODEL (BERT)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Google trained BERT on ALL of Wikipedia + Books                â”‚
â”‚                                                                 â”‚
â”‚  What it learned:                                               â”‚
â”‚  â€¢ Grammar and syntax                                           â”‚
â”‚  â€¢ Word meanings and relationships                              â”‚
â”‚  â€¢ Common knowledge ("Paris is in France")                      â”‚
â”‚  â€¢ Context understanding                                        â”‚
â”‚                                                                 â”‚
â”‚  Your task: Classify movie reviews as Positive/Negative         â”‚
â”‚                                                                 â”‚
â”‚  Transfer: Use BERT's language understanding,                   â”‚
â”‚            just teach it your specific task                     â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Fine-Tuning: A Deeper Transfer

**Feature Extraction**: Freeze pretrained layers, only train new head
**Fine-Tuning**: Also slightly update the pretrained layers

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚              Feature Extraction        Fine-Tuning              â”‚
â”‚                                                                 â”‚
â”‚   Head         [Train 100%]           [Train 100%]              â”‚
â”‚                                                                 â”‚
â”‚   Top layers   [Frozen â„ï¸]            [Train slowly]            â”‚
â”‚                                                                 â”‚
â”‚   Mid layers   [Frozen â„ï¸]            [Train slower]            â”‚
â”‚                                                                 â”‚
â”‚   Low layers   [Frozen â„ï¸]            [Frozen â„ï¸]               â”‚
â”‚                                                                 â”‚
â”‚   Pros:        Fast, works with       Better accuracy           â”‚
â”‚                little data                                      â”‚
â”‚   Cons:        Less accurate          Needs more data,          â”‚
â”‚                                       can overfit               â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# When to Use Transfer Learning

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              TRANSFER LEARNING DECISION GUIDE                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  You have IMAGES?                                               â”‚
â”‚  â†’ Use pretrained ResNet, EfficientNet, or ViT                  â”‚
â”‚  â†’ Works great even with 100 images!                            â”‚
â”‚                                                                 â”‚
â”‚  You have TEXT?                                                 â”‚
â”‚  â†’ Use pretrained BERT, RoBERTa, or use LLM APIs                â”‚
â”‚  â†’ Works great for classification, sentiment, etc.              â”‚
â”‚                                                                 â”‚
â”‚  You have TABULAR DATA (spreadsheets)?                          â”‚
â”‚  â†’ Transfer learning is less common                             â”‚
â”‚  â†’ Use AutoML instead (AutoGluon)                               â”‚
â”‚                                                                 â”‚
â”‚  You have AUDIO?                                                â”‚
â”‚  â†’ Use pretrained Whisper, Wav2Vec                              â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Transfer Learning Example Code

```python
from transformers import pipeline

# Load a pretrained sentiment classifier
classifier = pipeline("sentiment-analysis")

# Use it immediately - no training needed!
reviews = [
    "This movie was absolutely fantastic!",
    "Worst film I've ever seen.",
    "It was okay, nothing special."
]

for review in reviews:
    result = classifier(review)
    print(f"{review[:30]}... â†’ {result[0]['label']}")
```

**Output:**
```
This movie was absolutely fant... â†’ POSITIVE
Worst film I've ever seen.... â†’ NEGATIVE
It was okay, nothing special.... â†’ NEGATIVE
```

---

<!-- _class: lead -->

# Part 6: Putting It All Together

*A complete workflow*

---

# The Complete Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ML MODEL DEVELOPMENT WORKFLOW                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Step 1: Understand your data                                   â”‚
â”‚          â€¢ What type? (tabular, images, text)                   â”‚
â”‚          â€¢ How much? (100 samples vs 1 million)                 â”‚
â”‚                                                                 â”‚
â”‚  Step 2: Create a baseline                                      â”‚
â”‚          â€¢ Tabular: Logistic Regression or Random Forest        â”‚
â”‚          â€¢ Images/Text: Pretrained model (transfer learning)    â”‚
â”‚                                                                 â”‚
â”‚  Step 3: Evaluate with cross-validation                         â”‚
â”‚          â€¢ Get reliable accuracy estimates                      â”‚
â”‚          â€¢ Understand variance in performance                   â”‚
â”‚                                                                 â”‚
â”‚  Step 4: Try AutoML (if tabular)                                â”‚
â”‚          â€¢ Let AutoGluon find the best model                    â”‚
â”‚          â€¢ Compare to your baseline                             â”‚
â”‚                                                                 â”‚
â”‚  Step 5: Iterate and improve                                    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Netflix Movie Prediction: Full Example

```python
import pandas as pd
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier
from autogluon.tabular import TabularPredictor

# Load our movie data
movies = pd.read_csv('movies.csv')

# Baseline: Random Forest with cross-validation
rf = RandomForestClassifier(n_estimators=100)
baseline_scores = cross_val_score(rf, X, y, cv=5)
print(f"Baseline (RF): {baseline_scores.mean():.1%} Â± {baseline_scores.std():.1%}")

# AutoML: Let AutoGluon do its magic
predictor = TabularPredictor(label='success')
predictor.fit(movies, time_limit=300)
print(predictor.leaderboard())
```

---

# What Good Accuracy Looks Like

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              INTERPRETING YOUR RESULTS                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Random guessing:              50%                              â”‚
â”‚  Majority class baseline:      60%                              â”‚
â”‚  Simple model (Logistic Reg):  72%                              â”‚
â”‚  Better model (Random Forest): 78%                              â”‚
â”‚  AutoML (AutoGluon):           82%                              â”‚
â”‚  State-of-the-art:             85%                              â”‚
â”‚                                                                 â”‚
â”‚  Key questions:                                                 â”‚
â”‚  â€¢ Did you beat random guessing? âœ“                              â”‚
â”‚  â€¢ Did you beat majority class? âœ“                               â”‚
â”‚  â€¢ Is the improvement worth the complexity?                     â”‚
â”‚                                                                 â”‚
â”‚  82% might be amazing for some problems,                        â”‚
â”‚  and terrible for others. Context matters!                      â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Key Takeaways

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     TODAY'S KEY LESSONS                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  1. ALWAYS START WITH A BASELINE                                â”‚
â”‚     â†’ Simple models are your reference point                    â”‚
â”‚     â†’ You can't know if fancy is better without simple first    â”‚
â”‚                                                                 â”‚
â”‚  2. USE CROSS-VALIDATION                                        â”‚
â”‚     â†’ One test set can be misleading                            â”‚
â”‚     â†’ 5-fold CV gives reliable estimates                        â”‚
â”‚                                                                 â”‚
â”‚  3. TRY AUTOML FOR TABULAR DATA                                 â”‚
â”‚     â†’ AutoGluon does the hard work for you                      â”‚
â”‚     â†’ Great for prototyping and competitions                    â”‚
â”‚                                                                 â”‚
â”‚  4. USE TRANSFER LEARNING FOR IMAGES/TEXT                       â”‚
â”‚     â†’ Don't train from scratch                                  â”‚
â”‚     â†’ Pretrained models save time and work better               â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Common Mistakes to Avoid

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DON'T DO THIS!                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  âŒ Starting with deep learning before trying simple models     â”‚
â”‚                                                                 â”‚
â”‚  âŒ Evaluating on only one train/test split                     â”‚
â”‚                                                                 â”‚
â”‚  âŒ Tuning hyperparameters on the test set                      â”‚
â”‚     (This is cheating! Use a validation set)                    â”‚
â”‚                                                                 â”‚
â”‚  âŒ Training image/text models from scratch with small data     â”‚
â”‚                                                                 â”‚
â”‚  âŒ Ignoring the baseline ("My model gets 80%!" vs what?)       â”‚
â”‚                                                                 â”‚
â”‚  âŒ Over-engineering for tiny improvements                      â”‚
â”‚     (+0.5% accuracy isn't worth 10x complexity)                 â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Next Week Preview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      COMING UP: WEEK 8                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Model Evaluation & Deployment                                  â”‚
â”‚                                                                 â”‚
â”‚  â€¢ Confusion matrices (understanding errors)                    â”‚
â”‚  â€¢ Precision, Recall, F1 (beyond accuracy)                      â”‚
â”‚  â€¢ When accuracy is misleading                                  â”‚
â”‚  â€¢ Deploying your model to production                           â”‚
â”‚                                                                 â”‚
â”‚  You've built the model. Now how do you know it's REALLY good?  â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Lab Preview

**This week's hands-on exercises:**

1. **Build baselines**: Compare Logistic Regression, Decision Tree, Random Forest
2. **Cross-validate**: Use 5-fold CV to get reliable estimates
3. **Try AutoGluon**: Let it find the best model for Netflix data
4. **Transfer learning demo**: Use a pretrained model for text classification

**All code will be provided. Focus on understanding!**

---

<!-- _class: lead -->

# Questions?

**Key concepts:**
- Baseline models
- Cross-validation
- AutoML (AutoGluon)
- Transfer learning

**Remember**: Simple first, complex only if needed!
