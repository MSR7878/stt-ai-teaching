{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 10 Lab: Building ML APIs with FastAPI\n",
    "\n",
    "**CS 203: Software Tools and Techniques for AI**\n",
    "\n",
    "---\n",
    "\n",
    "## Lab Overview\n",
    "\n",
    "In this lab, you will learn to:\n",
    "1. **Build REST APIs** with FastAPI from scratch\n",
    "2. **Validate inputs** using Pydantic models\n",
    "3. **Serve ML models** via HTTP endpoints\n",
    "4. **Handle errors** gracefully\n",
    "5. **Test APIs** with automated tests\n",
    "\n",
    "**Goal**: Create a production-ready ML prediction API.\n",
    "\n",
    "---\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install \"fastapi[standard]\" scikit-learn joblib pytest httpx uvicorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: Understanding REST APIs\n",
    "\n",
    "Before building APIs, let's understand how they work.\n",
    "\n",
    "## 1.1 What is a REST API?\n",
    "\n",
    "```\n",
    "┌─────────────┐    HTTP Request     ┌─────────────┐\n",
    "│   Client    │ ─────────────────► │   Server    │\n",
    "│ (Browser,   │                     │  (FastAPI)  │\n",
    "│  Python,    │ ◄───────────────── │             │\n",
    "│  Mobile)    │    HTTP Response    │             │\n",
    "└─────────────┘                     └─────────────┘\n",
    "```\n",
    "\n",
    "**REST** = Representational State Transfer\n",
    "\n",
    "**Key concepts**:\n",
    "- **Resources**: Things you can access (e.g., `/users`, `/movies`, `/predictions`)\n",
    "- **HTTP Methods**: Actions on resources (GET, POST, PUT, DELETE)\n",
    "- **JSON**: Standard format for data exchange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.1 (Solved): Explore a Public API\n",
    "\n",
    "Let's call a public API to understand the request/response cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLVED EXAMPLE\n",
    "import requests\n",
    "\n",
    "# Call a public API\n",
    "response = requests.get(\"https://jsonplaceholder.typicode.com/posts/1\")\n",
    "\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "print(f\"Content-Type: {response.headers['Content-Type']}\")\n",
    "print(f\"\\nResponse Body:\")\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.2: HTTP Methods\n",
    "\n",
    "Match each HTTP method to its purpose:\n",
    "\n",
    "| Method | Purpose |\n",
    "|--------|----------|\n",
    "| GET | ? |\n",
    "| POST | ? |\n",
    "| PUT | ? |\n",
    "| DELETE | ? |\n",
    "\n",
    "Options: Create new resource, Read/retrieve data, Update existing resource, Remove resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR ANSWERS HERE\n",
    "http_methods = {\n",
    "    \"GET\": None,     # Replace None with purpose\n",
    "    \"POST\": None,\n",
    "    \"PUT\": None,\n",
    "    \"DELETE\": None\n",
    "}\n",
    "\n",
    "print(http_methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.3: Make a POST Request\n",
    "\n",
    "Create a new post using the JSONPlaceholder API.\n",
    "\n",
    "**Endpoint**: `https://jsonplaceholder.typicode.com/posts`\n",
    "\n",
    "**Data to send**:\n",
    "```python\n",
    "{\n",
    "    \"title\": \"My First Post\",\n",
    "    \"body\": \"This is the content of my post\",\n",
    "    \"userId\": 1\n",
    "}\n",
    "```\n",
    "\n",
    "Print the status code and response body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Train and Save an ML Model\n",
    "\n",
    "Before serving a model via API, we need to train and save it.\n",
    "\n",
    "## 2.1 Train a Simple Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.1 (Solved): Train Iris Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLVED EXAMPLE\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "# Load data\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris.data, iris.target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f\"Model accuracy: {accuracy:.2%}\")\n",
    "\n",
    "# Save model\n",
    "joblib.dump(model, \"iris_model.pkl\")\n",
    "print(\"Model saved to iris_model.pkl\")\n",
    "\n",
    "# Show feature names and target names\n",
    "print(f\"\\nFeatures: {iris.feature_names}\")\n",
    "print(f\"Classes: {iris.target_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.2: Test the Saved Model\n",
    "\n",
    "Load the saved model and make a prediction for:\n",
    "- sepal_length: 5.1\n",
    "- sepal_width: 3.5\n",
    "- petal_length: 1.4\n",
    "- petal_width: 0.2\n",
    "\n",
    "Print the predicted class name and probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: Build Your First FastAPI\n",
    "\n",
    "Now let's create an API to serve predictions.\n",
    "\n",
    "## 3.1 Creating the API\n",
    "\n",
    "We'll write FastAPI code to files and run them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.1 (Solved): Hello World API\n",
    "\n",
    "Create a simple FastAPI application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLVED EXAMPLE\n",
    "# Write the API code to a file\n",
    "\n",
    "api_code = '''\n",
    "from fastapi import FastAPI\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.get(\"/\")\n",
    "def read_root():\n",
    "    return {\"message\": \"Hello, FastAPI!\"}\n",
    "\n",
    "@app.get(\"/hello/{name}\")\n",
    "def greet(name: str):\n",
    "    return {\"greeting\": f\"Hello, {name}!\"}\n",
    "'''\n",
    "\n",
    "with open(\"main_hello.py\", \"w\") as f:\n",
    "    f.write(api_code)\n",
    "\n",
    "print(\"Created main_hello.py\")\n",
    "print(\"\\nTo run: fastapi dev main_hello.py\")\n",
    "print(\"Then visit: http://127.0.0.1:8000/docs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.2: Add Query Parameters\n",
    "\n",
    "Modify the API to add an endpoint `/search` that accepts:\n",
    "- `keyword` (required string)\n",
    "- `limit` (optional integer, default 10)\n",
    "\n",
    "Return: `{\"keyword\": keyword, \"limit\": limit}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Write the updated API code to a file\n",
    "\n",
    "api_code = '''\n",
    "from fastapi import FastAPI\n",
    "from typing import Optional\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.get(\"/\")\n",
    "def read_root():\n",
    "    return {\"message\": \"Hello, FastAPI!\"}\n",
    "\n",
    "# ADD YOUR /search ENDPOINT HERE\n",
    "\n",
    "'''\n",
    "\n",
    "with open(\"main_search.py\", \"w\") as f:\n",
    "    f.write(api_code)\n",
    "\n",
    "print(\"Created main_search.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 4: Input Validation with Pydantic\n",
    "\n",
    "Pydantic models validate incoming data automatically.\n",
    "\n",
    "## 4.1 Creating Request Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4.1 (Solved): Pydantic Model for Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLVED EXAMPLE\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional, List\n",
    "\n",
    "class PredictionInput(BaseModel):\n",
    "    \"\"\"Input schema for iris prediction.\"\"\"\n",
    "    sepal_length: float = Field(..., gt=0, lt=10, description=\"Sepal length in cm\")\n",
    "    sepal_width: float = Field(..., gt=0, lt=10, description=\"Sepal width in cm\")\n",
    "    petal_length: float = Field(..., gt=0, lt=10, description=\"Petal length in cm\")\n",
    "    petal_width: float = Field(..., gt=0, lt=10, description=\"Petal width in cm\")\n",
    "    \n",
    "    class Config:\n",
    "        json_schema_extra = {\n",
    "            \"example\": {\n",
    "                \"sepal_length\": 5.1,\n",
    "                \"sepal_width\": 3.5,\n",
    "                \"petal_length\": 1.4,\n",
    "                \"petal_width\": 0.2\n",
    "            }\n",
    "        }\n",
    "\n",
    "class PredictionOutput(BaseModel):\n",
    "    \"\"\"Output schema for iris prediction.\"\"\"\n",
    "    species: str\n",
    "    confidence: float\n",
    "    probabilities: List[float]\n",
    "\n",
    "# Test the model\n",
    "valid_input = PredictionInput(\n",
    "    sepal_length=5.1,\n",
    "    sepal_width=3.5,\n",
    "    petal_length=1.4,\n",
    "    petal_width=0.2\n",
    ")\n",
    "print(f\"Valid input: {valid_input}\")\n",
    "\n",
    "# Test validation error\n",
    "try:\n",
    "    invalid_input = PredictionInput(\n",
    "        sepal_length=-1.0,  # Invalid: negative\n",
    "        sepal_width=3.5,\n",
    "        petal_length=1.4,\n",
    "        petal_width=0.2\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"\\nValidation error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4.2: Create a Batch Prediction Model\n",
    "\n",
    "Create a Pydantic model `BatchPredictionInput` that accepts a list of `PredictionInput` items.\n",
    "\n",
    "Test it with 3 sample flowers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 5: Complete ML Prediction API\n",
    "\n",
    "Now let's put it all together.\n",
    "\n",
    "## 5.1 The Complete API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5.1 (Solved): Full ML API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLVED EXAMPLE\n",
    "# Write the complete ML API to a file\n",
    "\n",
    "ml_api_code = '''\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "# Create FastAPI app\n",
    "app = FastAPI(\n",
    "    title=\"Iris Species Prediction API\",\n",
    "    description=\"Predict Iris flower species from measurements\",\n",
    "    version=\"1.0.0\"\n",
    ")\n",
    "\n",
    "# Global model variable\n",
    "model = None\n",
    "SPECIES_NAMES = [\"setosa\", \"versicolor\", \"virginica\"]\n",
    "\n",
    "# Pydantic models\n",
    "class PredictionInput(BaseModel):\n",
    "    sepal_length: float = Field(..., gt=0, lt=10)\n",
    "    sepal_width: float = Field(..., gt=0, lt=10)\n",
    "    petal_length: float = Field(..., gt=0, lt=10)\n",
    "    petal_width: float = Field(..., gt=0, lt=10)\n",
    "    \n",
    "    class Config:\n",
    "        json_schema_extra = {\n",
    "            \"example\": {\n",
    "                \"sepal_length\": 5.1,\n",
    "                \"sepal_width\": 3.5,\n",
    "                \"petal_length\": 1.4,\n",
    "                \"petal_width\": 0.2\n",
    "            }\n",
    "        }\n",
    "\n",
    "class PredictionOutput(BaseModel):\n",
    "    species: str\n",
    "    confidence: float\n",
    "    probabilities: List[float]\n",
    "\n",
    "# Startup event\n",
    "@app.on_event(\"startup\")\n",
    "def load_model():\n",
    "    global model\n",
    "    model_path = Path(\"iris_model.pkl\")\n",
    "    if model_path.exists():\n",
    "        model = joblib.load(model_path)\n",
    "        print(\"Model loaded successfully!\")\n",
    "    else:\n",
    "        print(\"Warning: Model file not found!\")\n",
    "\n",
    "# Health check\n",
    "@app.get(\"/health\")\n",
    "def health_check():\n",
    "    return {\n",
    "        \"status\": \"healthy\",\n",
    "        \"model_loaded\": model is not None\n",
    "    }\n",
    "\n",
    "# Prediction endpoint\n",
    "@app.post(\"/predict\", response_model=PredictionOutput)\n",
    "def predict(input_data: PredictionInput):\n",
    "    if model is None:\n",
    "        raise HTTPException(status_code=503, detail=\"Model not loaded\")\n",
    "    \n",
    "    # Prepare features\n",
    "    features = [[\n",
    "        input_data.sepal_length,\n",
    "        input_data.sepal_width,\n",
    "        input_data.petal_length,\n",
    "        input_data.petal_width\n",
    "    ]]\n",
    "    \n",
    "    # Predict\n",
    "    prediction = model.predict(features)[0]\n",
    "    probabilities = model.predict_proba(features)[0]\n",
    "    \n",
    "    return {\n",
    "        \"species\": SPECIES_NAMES[prediction],\n",
    "        \"confidence\": float(max(probabilities)),\n",
    "        \"probabilities\": probabilities.tolist()\n",
    "    }\n",
    "'''\n",
    "\n",
    "with open(\"ml_api.py\", \"w\") as f:\n",
    "    f.write(ml_api_code)\n",
    "\n",
    "print(\"Created ml_api.py\")\n",
    "print(\"\\nTo run: fastapi dev ml_api.py\")\n",
    "print(\"Then visit: http://127.0.0.1:8000/docs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5.2: Add Batch Prediction Endpoint\n",
    "\n",
    "Add a `/predict/batch` endpoint to the API that:\n",
    "1. Accepts a list of prediction inputs\n",
    "2. Returns a list of predictions\n",
    "3. Includes a count of predictions made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Add the batch endpoint code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 6: Error Handling\n",
    "\n",
    "Production APIs need robust error handling.\n",
    "\n",
    "## 6.1 Handling Common Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6.1 (Solved): Error Handling Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLVED EXAMPLE\n",
    "# Common error handling patterns\n",
    "\n",
    "error_handling_code = '''\n",
    "from fastapi import FastAPI, HTTPException\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "def predict(input_data: PredictionInput):\n",
    "    try:\n",
    "        # Check model is loaded\n",
    "        if model is None:\n",
    "            logger.error(\"Prediction failed: Model not loaded\")\n",
    "            raise HTTPException(\n",
    "                status_code=503,\n",
    "                detail=\"Model not available. Please try again later.\"\n",
    "            )\n",
    "        \n",
    "        # Log the request\n",
    "        logger.info(f\"Prediction request: {input_data.dict()}\")\n",
    "        \n",
    "        # Make prediction\n",
    "        features = [[...]]  # Prepare features\n",
    "        prediction = model.predict(features)[0]\n",
    "        \n",
    "        return {\"species\": SPECIES_NAMES[prediction]}\n",
    "        \n",
    "    except HTTPException:\n",
    "        raise  # Re-raise HTTP exceptions\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Prediction error: {e}\", exc_info=True)\n",
    "        raise HTTPException(\n",
    "            status_code=500,\n",
    "            detail=\"Internal server error during prediction\"\n",
    "        )\n",
    "'''\n",
    "\n",
    "print(\"Error handling patterns:\")\n",
    "print(\"1. Log all errors\")\n",
    "print(\"2. Return appropriate status codes (503 for unavailable, 500 for errors)\")\n",
    "print(\"3. Never expose internal error details to clients\")\n",
    "print(\"4. Use try-except to catch unexpected errors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6.2: Match Status Codes to Scenarios\n",
    "\n",
    "Match each scenario to the correct HTTP status code:\n",
    "\n",
    "| Scenario | Status Code |\n",
    "|----------|-------------|\n",
    "| Model loaded, prediction successful | ? |\n",
    "| Invalid input (negative values) | ? |\n",
    "| Model file not found | ? |\n",
    "| Server crashed during prediction | ? |\n",
    "\n",
    "Options: 200, 422, 500, 503"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR ANSWERS HERE\n",
    "scenarios = {\n",
    "    \"prediction_successful\": None,\n",
    "    \"invalid_input\": None,\n",
    "    \"model_not_found\": None,\n",
    "    \"server_crashed\": None\n",
    "}\n",
    "\n",
    "print(scenarios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 7: Testing Your API\n",
    "\n",
    "Automated tests verify your API works correctly.\n",
    "\n",
    "## 7.1 Writing API Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7.1 (Solved): Test with TestClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLVED EXAMPLE\n",
    "# Write tests to a file\n",
    "\n",
    "test_code = '''\n",
    "from fastapi.testclient import TestClient\n",
    "from ml_api import app\n",
    "\n",
    "client = TestClient(app)\n",
    "\n",
    "def test_health_check():\n",
    "    response = client.get(\"/health\")\n",
    "    assert response.status_code == 200\n",
    "    data = response.json()\n",
    "    assert \"status\" in data\n",
    "    assert \"model_loaded\" in data\n",
    "\n",
    "def test_predict_setosa():\n",
    "    \"\"\"Test prediction for setosa species.\"\"\"\n",
    "    payload = {\n",
    "        \"sepal_length\": 5.1,\n",
    "        \"sepal_width\": 3.5,\n",
    "        \"petal_length\": 1.4,\n",
    "        \"petal_width\": 0.2\n",
    "    }\n",
    "    response = client.post(\"/predict\", json=payload)\n",
    "    assert response.status_code == 200\n",
    "    data = response.json()\n",
    "    assert \"species\" in data\n",
    "    assert \"confidence\" in data\n",
    "    assert data[\"species\"] == \"setosa\"\n",
    "\n",
    "def test_predict_invalid_input():\n",
    "    \"\"\"Test that invalid input returns 422.\"\"\"\n",
    "    payload = {\n",
    "        \"sepal_length\": -1.0,  # Invalid\n",
    "        \"sepal_width\": 3.5,\n",
    "        \"petal_length\": 1.4,\n",
    "        \"petal_width\": 0.2\n",
    "    }\n",
    "    response = client.post(\"/predict\", json=payload)\n",
    "    assert response.status_code == 422\n",
    "'''\n",
    "\n",
    "with open(\"test_api.py\", \"w\") as f:\n",
    "    f.write(test_code)\n",
    "\n",
    "print(\"Created test_api.py\")\n",
    "print(\"\\nTo run tests: pytest test_api.py -v\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7.2: Write Additional Tests\n",
    "\n",
    "Add tests for:\n",
    "1. Missing required field (should return 422)\n",
    "2. Versicolor prediction (use values: 6.0, 2.7, 4.5, 1.5)\n",
    "3. Virginica prediction (use values: 7.2, 3.2, 6.0, 1.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 8: Deployment\n",
    "\n",
    "Running the API in production.\n",
    "\n",
    "## 8.1 Production Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8.1: Create Requirements File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create requirements.txt\n",
    "requirements = \"\"\"fastapi==0.104.1\n",
    "uvicorn[standard]==0.24.0\n",
    "pydantic==2.5.0\n",
    "scikit-learn==1.3.2\n",
    "joblib==1.3.2\n",
    "pytest==7.4.3\n",
    "httpx==0.25.1\n",
    "\"\"\"\n",
    "\n",
    "with open(\"requirements.txt\", \"w\") as f:\n",
    "    f.write(requirements)\n",
    "\n",
    "print(\"Created requirements.txt\")\n",
    "print(\"\\nTo install: pip install -r requirements.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8.2: Create Dockerfile (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Create a Dockerfile for containerizing the API\n",
    "\n",
    "dockerfile = \"\"\"\n",
    "# YOUR DOCKERFILE HERE\n",
    "\"\"\"\n",
    "\n",
    "# Hint: Use python:3.10-slim as base image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Summary\n",
    "\n",
    "In this lab, you learned:\n",
    "\n",
    "1. **REST API fundamentals**: HTTP methods, status codes, JSON\n",
    "2. **FastAPI basics**: Routes, path/query parameters\n",
    "3. **Pydantic validation**: Input/output schemas with constraints\n",
    "4. **ML model serving**: Loading models, making predictions\n",
    "5. **Error handling**: Logging, appropriate status codes\n",
    "6. **Testing**: Using TestClient for API tests\n",
    "7. **Deployment**: Requirements, production server\n",
    "\n",
    "## Next Week\n",
    "\n",
    "**Week 11: Git & CI/CD**\n",
    "\n",
    "We'll learn to:\n",
    "- Automate testing with GitHub Actions\n",
    "- Set up CI/CD pipelines\n",
    "- Deploy APIs automatically\n",
    "\n",
    "---\n",
    "\n",
    "## Submission\n",
    "\n",
    "Submit:\n",
    "1. This completed notebook\n",
    "2. Your `ml_api.py` file\n",
    "3. Your `test_api.py` file\n",
    "4. Screenshot of Swagger UI (/docs page)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
